{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c0706b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d19356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad7e6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = pd.read_csv('categorical.csv')\n",
    "numerical = pd.read_csv('numerical.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5718eb1",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa530ca2",
   "metadata": {},
   "source": [
    "### 1.1 Look critically at the dtypes of numerical and categorical columns and make changes where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b2b360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fcd8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical['INCOME'] = numerical['INCOME'].astype(int)\n",
    "numerical['WEALTH2'] = numerical['WEALTH2'].astype(int)\n",
    "numerical['MSA'] = numerical['MSA'].astype(int)\n",
    "numerical['RAMNTALL'] = numerical['RAMNTALL'].astype(int)\n",
    "numerical['MAXRAMNT'] = numerical['MAXRAMNT'].astype(int)\n",
    "numerical['TARGET_D'] = numerical['TARGET_D'].astype(int)\n",
    "numerical['CLUSTER2'] = numerical['CLUSTER2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08381974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbcd2ac",
   "metadata": {},
   "source": [
    "### 1.2 Concatenate numerical and categorical back together again for your X dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4001efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([numerical, categorical], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e30472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f328ebc",
   "metadata": {},
   "source": [
    "### 1.3 Designate the TargetB as y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2864fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['TARGET_B']\n",
    "X = data.drop(['TARGET_B'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421d862",
   "metadata": {},
   "source": [
    "### 1.4 Split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f94e791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58e549",
   "metadata": {},
   "source": [
    "### 1.5 Split further into train_num and train_cat.  Also test_num and test_cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "543c13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = X_train.select_dtypes(include='number')\n",
    "train_cat = X_train.select_dtypes(include='object')\n",
    "\n",
    "test_num = X_test.select_dtypes(include='number')\n",
    "test_cat = X_test.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b7bcc",
   "metadata": {},
   "source": [
    "### 1.6 Scale the features either by using MinMax Scaler or a Standard Scaler. (train_num, test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb62b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_fit = MinMaxScaler().fit(train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45dfaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_trans = minmax_fit.transform(train_num)\n",
    "test_num_trans = minmax_fit.transform(test_num)\n",
    "\n",
    "train_num_trans = pd.DataFrame(train_num_trans, columns=train_num.columns)\n",
    "test_num_trans = pd.DataFrame(test_num_trans, columns=train_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50162ca2",
   "metadata": {},
   "source": [
    "### 1.7 Encode the categorical features using One-Hot Encoding or Ordinal Encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8e29bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_fit = OneHotEncoder(drop='first', handle_unknown='ignore').fit(train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f09ca0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1, 4, 10, 11, 13, 14, 15, 16, 17, 23, 24, 25, 26, 27, 28] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_cat_enc = onehot_fit.transform(train_cat).toarray()\n",
    "train_cat_enc = pd.DataFrame(train_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))\n",
    "\n",
    "test_cat_enc = onehot_fit.transform(test_cat).toarray()\n",
    "test_cat_enc = pd.DataFrame(test_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81160c0",
   "metadata": {},
   "source": [
    "### 1.8 Re-concatenate train_num and train_cat as X_train as well as test_num and test_cat as X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1006e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([train_cat_enc, train_num_trans], axis=1)\n",
    "X_test = pd.concat([test_cat_enc, test_num_trans], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db0abffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58677d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba476cbd",
   "metadata": {},
   "source": [
    "### 1.9 Fit a logistic regression model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10a90bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f8fddf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9d3ff494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793009484881832"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3bd2c3",
   "metadata": {},
   "source": [
    "> The accuracy score is pretty high, although we shouldnÂ´t rely just on this metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f561e36c",
   "metadata": {},
   "source": [
    "# 2. Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24093620",
   "metadata": {},
   "source": [
    "### 2.1 Check for the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4189bd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1     4843\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TARGET_B'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21402dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0 = data[data['TARGET_B'] == 0]\n",
    "category_1 = data[data['TARGET_B'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042464ca",
   "metadata": {},
   "source": [
    "### 2.2 Strategy 1: Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "257094c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_0_undersampled = resample(category_0,\n",
    "                                   replace=False,\n",
    "                                   n_samples = len(category_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48b23566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_downsampled = pd.concat([category_0_undersampled, category_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45cc4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1, 4, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9081527347781218"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_downsampled['TARGET_B']\n",
    "X = data_downsampled.drop(['TARGET_B'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_num = X_train.select_dtypes(include='number')\n",
    "train_cat = X_train.select_dtypes(include='object')\n",
    "\n",
    "test_num = X_test.select_dtypes(include='number')\n",
    "test_cat = X_test.select_dtypes(include='object')\n",
    "\n",
    "minmax_fit = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num_trans = minmax_fit.transform(train_num)\n",
    "test_num_trans = minmax_fit.transform(test_num)\n",
    "\n",
    "train_num_trans = pd.DataFrame(train_num_trans, columns=train_num.columns)\n",
    "test_num_trans = pd.DataFrame(test_num_trans, columns=train_num.columns)\n",
    "\n",
    "onehot_fit = OneHotEncoder(drop='first', handle_unknown='ignore').fit(train_cat)\n",
    "\n",
    "train_cat_enc = onehot_fit.transform(train_cat).toarray()\n",
    "train_cat_enc = pd.DataFrame(train_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))\n",
    "\n",
    "test_cat_enc = onehot_fit.transform(test_cat).toarray()\n",
    "test_cat_enc = pd.DataFrame(test_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))\n",
    "\n",
    "X_train = pd.concat([train_cat_enc, train_num_trans], axis=1)\n",
    "X_test = pd.concat([test_cat_enc, test_num_trans], axis=1)\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ca28916",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78b8e346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9081527347781218"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752e7e7",
   "metadata": {},
   "source": [
    "### 2.3 Strategy 2: Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f759bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_1_oversampled = resample(category_1,\n",
    "                                  replace=True,\n",
    "                                  n_samples = len(category_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cfc7e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_upsampled = pd.concat([category_0, category_1_oversampled], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5488d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1, 10, 14, 15, 16, 19, 20, 21, 22, 24, 27, 28] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y = data_upsampled['TARGET_B']\n",
    "X = data_upsampled.drop(['TARGET_B'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_num = X_train.select_dtypes(include='number')\n",
    "train_cat = X_train.select_dtypes(include='object')\n",
    "\n",
    "test_num = X_test.select_dtypes(include='number')\n",
    "test_cat = X_test.select_dtypes(include='object')\n",
    "\n",
    "minmax_fit = MinMaxScaler().fit(train_num)\n",
    "\n",
    "train_num_trans = minmax_fit.transform(train_num)\n",
    "test_num_trans = minmax_fit.transform(test_num)\n",
    "\n",
    "train_num_trans = pd.DataFrame(train_num_trans, columns=train_num.columns)\n",
    "test_num_trans = pd.DataFrame(test_num_trans, columns=train_num.columns)\n",
    "\n",
    "onehot_fit = OneHotEncoder(drop='first', handle_unknown='ignore').fit(train_cat)\n",
    "\n",
    "train_cat_enc = onehot_fit.transform(train_cat).toarray()\n",
    "train_cat_enc = pd.DataFrame(train_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))\n",
    "\n",
    "test_cat_enc = onehot_fit.transform(test_cat).toarray()\n",
    "test_cat_enc = pd.DataFrame(test_cat_enc, columns=onehot_fit.get_feature_names_out(input_features=train_cat.columns))\n",
    "\n",
    "X_train = pd.concat([train_cat_enc, train_num_trans], axis=1)\n",
    "X_test = pd.concat([test_cat_enc, test_num_trans], axis=1)\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38119095",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "97faac30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950314673733024"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
